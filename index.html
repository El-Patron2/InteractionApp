<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ConversAI - Your Intelligent Companion</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Roboto', sans-serif;
            background-color: #0d0d0d; /* Dark background */
            color: #e0e0e0; /* Light text color */
            line-height: 1.6;
            padding: 20px;
            margin: 0;
        }
        h1 {
            text-align: center;
            font-size: 2.5em;
            margin-bottom: 20px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);
        }
        .container {
            max-width: 800px;
            margin: auto;
            background-color: #1a1a1a; /* Lighter dark background */
            border-radius: 10px;
            padding: 20px;
            box-shadow: 0 4px 10px rgba(255, 255, 255, 0.1);
        }
        .section {
            background-color: #242424; /* Section background */
            border-radius: 8px;
            padding: 20px;
            margin-bottom: 20px;
        }
        h2 {
            color: #4CAF50; /* Elegant green for headings */
            font-size: 1.8em;
            text-align: center;
        }
        button {
            background-color: #007BFF; /* Button color */
            color: white;
            padding: 10px 15px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-size: 1em;
            transition: background-color 0.3s ease, transform 0.1s ease; /* Haptic feedback effect */
        }
        button:hover {
            background-color: #0056b3; /* Darker blue on hover */
        }
        button:active {
            transform: scale(0.95); /* Haptic feedback effect */
        }
        input[type="file"], textarea {
            width: calc(100% - 20px);
            padding: 10px;
            margin-bottom: 10px;
            border-radius: 4px;
            border: none;
        }
        #recordingStatus {
            text-align: center;
            font-weight: bold;
        }
        .footer {
           text-align:center; 
           margin-top:20px; 
           font-size:.8em; 
           color:#aaa; 
           padding-top:.5em; 
           border-top:.5px solid #444
       }
    </style>
</head>
<body>
    <h1>ConversAI - Your Intelligent Companion</h1>

    <div class="container">
        <div class="section">
            <h2>Voice Recording</h2>
            <button id="startRecording">Start Recording</button>
            <button id="stopRecording" disabled>Stop Recording</button>
            <div id="recordingStatus"></div>
        </div>

        <div class="section">
            <h2>Audio File Transcription</h2>
            <input type="file" id="audioFile" accept="audio/*">
            <button id="transcribeFile">Transcribe File</button>
            <div id="transcriptionResult"></div>
        </div>

        <div class="section">
            <h2>Text to Speech</h2>
            <textarea id="textToSpeech" rows="4" placeholder="Enter text to convert to speech"></textarea>
            <button id="generateSpeech">Generate Speech</button>
            <audio id="audioPlayer" controls style="display:none;"></audio>
        </div>

    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/axios/0.21.1/axios.min.js"></script>
    <script>
        let mediaRecorder;
        let audioChunks = [];

        document.getElementById('startRecording').addEventListener('click', startRecording);
        document.getElementById('stopRecording').addEventListener('click', stopRecording);
        document.getElementById('transcribeFile').addEventListener('click', transcribeFile);
        document.getElementById('generateSpeech').addEventListener('click', generateSpeech);

        async function startRecording() {
          const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
          mediaRecorder = new MediaRecorder(stream);
          mediaRecorder.ondataavailable = event => {
              audioChunks.push(event.data);
          };
          mediaRecorder.onstop = handleRecordingStop;

          mediaRecorder.start();
          document.getElementById('startRecording').disabled = true;
          document.getElementById('stopRecording').disabled = false;

          document.getElementById('recordingStatus').textContent = 'Recording...';
      }

      function stopRecording() {
          mediaRecorder.stop();
          document.getElementById('startRecording').disabled = false;
          document.getElementById('stopRecording').disabled = true;

          document.getElementById('recordingStatus').textContent = 'Recording stopped.';
      }

      async function handleRecordingStop() {
          const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
          audioChunks = [];
          
          const formData = new FormData();
          formData.append('audio', audioBlob, 'recording.webm');
          
          try {
              const response = await axios.post('/transcribe', formData);
              document.getElementById('transcriptionResult').textContent = response.data.transcription || 'No transcription available.';
              alert("Transcription successful!");
              
              // Clear the transcription result after a few seconds
              setTimeout(() => { 
                  document.getElementById('transcriptionResult').textContent = ''; 
              }, 5000);
              
              // Optionally play back the recorded audio
              const audioURL = URL.createObjectURL(audioBlob);
              const audioPlayer = new Audio(audioURL);
              audioPlayer.play();
              
              // Provide user feedback
              document.getElementById('recordingStatus').textContent += ' Playback started.';
              
              setTimeout(() => { 
                  document.getElementById('recordingStatus').textContent = ''; 
              }, 5000);

              
      } catch (error) {
              console.error('Error:', error);
              document.getElementById('transcriptionResult').textContent = 'Error during transcription.';
          }
      }

      async function transcribeFile() {
          const fileInput = document.getElementById('audioFile');
          const file = fileInput.files[0];
          if (!file) {
              alert('Please select an audio file.');
              return;
          }
          const formData = new FormData();
          formData.append('audio', file);
          try {
              const response = await axios.post('/transcribe', formData);
              document.getElementById('transcriptionResult').textContent = response.data.transcription || 'No transcription available.';
          } catch (error) {
              console.error('Error:', error);
              document.getElementById('transcriptionResult').textContent = 'Error during transcription.';
          }
      }

      async function generateSpeech() {
          const text = document.getElementById('textToSpeech').value.trim();
          if (!text) {
              alert('Please enter text to convert to speech.');
              return;
          }
          try {
              const response = await axios.post('/generate-speech', { text }, { responseType: 'blob' });
              
               // Create a URL for the audio blob
               const audioUrl = URL.createObjectURL(response.data);
               
               // Set the source of the audio player and display it
               const audioPlayer = document.getElementById('audioPlayer');
               audioPlayer.src = audioUrl; 
               audioPlayer.style.display = 'block'; 
          
         } catch (error) {
               console.error('Error:', error);
               alert('Error generating speech.');
         }
     }
    </script>

    <div class="footer">
       &copy; 2024 ConversAI. All rights reserved.
   </div>

</body>
</html>
